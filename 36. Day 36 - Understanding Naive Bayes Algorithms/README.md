
## **DAY 36 (24 Oct 2023):**
### Topic: Understanding Naive Bayes Classifiers
Naive Bayes, is a classification technique based on Bayes' Theorem with the assumption of independence among predictors. This algorithm is particularly useful when working with text data.

**Topics Discussed in Notes:**
1. Why do we need Naive Bayes
2. Concept of how it works
3. Mathematical Intuition of Naive Bayes
4. Solving an Example on Naive Bayes
5. Other Bayes Classifiers
   - Gaussian Naive Bayes Classifier
   - Multinomial Naive Bayes Classifier
   - Bernoulli Naive Bayes Classifier

**Key Takeaways:**
1. It's based on the principles of Bayes' Theorem( P(A|B) = P(B|A) * P(A) / P(B). ), a probability theory that helps determine the likelihood of an event occurring based on prior knowledge.

2. The "naive" aspect in its name comes from the assumption of independence among the features, meaning that the presence of a particular feature in a class is independent of the presence of other features. This assumption simplifies the computation, making it more efficient and less complex.

3. Gaussian Naive Bayes: Assumes that the features follow a normal distribution. This is suitable for continuous features.

4. Multinomial Naive Bayes: Suitable for discrete features, often used for text classification, where each feature represents the frequency with which a term appears.

5. Bernoulli Naive Bayes: Assumes that the features are binary or categorical. It is particularly useful for document classification tasks. Check out the notes for more.

Check out the Notes for More :)

Detailed Notes: [Day 36 Commit](https://github.com/ds-teja/100_Days_MLDL/tree/main/36.%20Day%2036%20-%20Understanding%20Naive%20Bayes%20Algorithms)

LinkedIn post: [Day 36 Update](https://www.linkedin.com/feed/update/urn:li:activity:7123044150786064384?utm_source=share&utm_medium=member_desktop)

---