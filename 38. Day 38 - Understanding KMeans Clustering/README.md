
## **DAY 38 (26 Oct 2023):**
### Topic: Understanding K-Means Clustering
Today, I dived into the world of K-Means clustering, an essential unsupervised learning algorithm. K-Means is a partitioning clustering algorithm that aims to divide n data points into k clusters.

**Topics Discussed in Notes:**
1. Concept of K-Means Clustering
2. Math Intuition Behind K-Means
3. Cluster Building Process
4. Edge Case Scenarios of K-Means
5. Challenges and Improvements in K-Means

**Key Takeaways:**
1. The algorithm involves the following steps:
- Initialization: Randomly select k points as cluster centers.
- Assignment: Assign each data point to the nearest cluster center.
- Update: Recalculate the cluster centers as the mean of all data points in the cluster.
- Repeat: Iterate the assignment and update steps until convergence.

2. K-Means can efficiently handle large datasets. It's computationally faster, making it suitable for time-sensitive tasks.

3. Results can vary based on the initial cluster centers. It assumes that clusters are spherical and of equal size, which might not always reflect real-world scenarios.

Check out the Below Notes for more :)

Detailed Notes: [Day 38 Commit](https://github.com/ds-teja/100_Days_MLDL/tree/main/38.%20Day%2038%20-%20Understanding%20KMeans%20Clustering)

LinkedIn post: [Day 38 Update](https://www.linkedin.com/feed/update/urn:li:activity:7123513607182548992?utm_source=share&utm_medium=member_desktop)
