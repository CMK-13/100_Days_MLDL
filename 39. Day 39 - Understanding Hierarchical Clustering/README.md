
## **DAY 39 (27 Oct 2023):**
### Topic: Understanding Hierarchical Clustering

Hierarchical Clustering is an unsupervised machine-learning algorithm that creates a hierarchical structure of clusters. It builds a tree-like structure (dendrogram) to visualize the relationships among the data points.

**Topics Discussed in Notes:**
1. Concept of Hierarchical Clustering
2. Understanding Algorithm
3. Understanding Linkage Methods

**Key Takeaways:**
1. Hierarchical Clustering involves two types: Agglomerative and Divisive. Agglomerative begins with treating each data point as a single cluster and sequentially merges the closest pairs of clusters. Divisive works in the opposite way, starting with a single cluster and then recursively dividing into smaller clusters.

2. Core steps of Hierarchical Clustering:
- Use a distance metric (Euclidean, Manhattan, etc.) to calculate the distance between data points. The method for calculating the distance between clusters greatly impacts the results.
- Build a matrix representing the distances between all data points.
- Decide the criteria for merging clusters (Single, Complete, Average, Ward's Method).
- Visualize the hierarchical tree structure, depicting the sequence of cluster mergers.

Check out the Notes for More :)

Detailed Notes: [Day 39 Commit](https://github.com/ds-teja/100_Days_MLDL/tree/main/39.%20Day%2039%20-%20Understanding%20Hierarchical%20Clustering)

LinkedIn post: [Day 39 Update](https://www.linkedin.com/posts/ravi6123_understanding-hierarchical-clustering-activity-7123709489433772033-kEJf?utm_source=share&utm_medium=member_desktop)

---