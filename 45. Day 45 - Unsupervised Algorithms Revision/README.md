## **DAY 45 (1 Nov 2023):**
### Topic: UnSupervised Algorithms Revision

### Key Takeaways

**Clustering Algorithms**
K-Means Clustering: Partition data points into distinct groups, iteratively assigns data points to the nearest cluster center, requires the number of clusters as input, simple and efficient for large datasets, sensitive to initial cluster centers and outliers.

Hierarchical Clustering: Build a hierarchy of clusters, agglomerative or divisive approaches, provides a dendrogram for visualizing clusters, no need to specify the number of clusters in advance, computationally expensive for large datasets.

**Dimensionality Reduction Algorithms**
Principal Component Analysis (PCA): Reduce the dimensionality of the data, finds the orthogonal components that capture maximum variance, retains most relevant information in fewer dimensions, simplifies data visualization and reduces computational complexity, may not be effective for nonlinear data.

t-Distributed Stochastic Neighbor Embedding (t-SNE): Visualize high-dimensional data in a low-dimensional space, minimizes the divergence between the distributions of high and low-dimensional data, preserves the local structure of the data, effective for visualizing complex relationships in data, computationally intensive for large datasets.

**Association Rule Learning Algorithms**
Apriori Algorithm: Discover frequent patterns in a dataset, generates candidate itemsets and prunes infrequent ones, utilizes support, confidence, and lift for rule generation, effective for market basket analysis and recommendation systems, computationally expensive for large itemsets.

Detailed Notes: [Day 45 Commit](https://github.com/ds-teja/100_Days_MLDL/tree/main/45.%20Day%2045%20-%20Unsupervised%20Algorithms%20Revision)

LinkedIn post: [Day 45 Update](https://www.linkedin.com/posts/ravi6123_unsupervised-algorithms-quick-summary-activity-7125901882861981696-FE6m?utm_source=share&utm_medium=member_desktop)
